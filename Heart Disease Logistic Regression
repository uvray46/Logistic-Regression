%matplotlib inline
#
# data manipulation and math
#
import numpy as np
import scipy as sp
import pandas as pd
#
# plotting and visualization
#
import matplotlib as mpl
import matplotlib.cm as cm
from matplotlib.colors import ListedColormap
import matplotlib.pyplot as plt
import seaborn as sns
#
# modeling
#
from sklearn.preprocessing import OneHotEncoder as OHE
import sklearn.model_selection
from sklearn.model_selection import train_test_split, KFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Pandas display options
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)

# Matplotlib options
plt.rcParams['figure.figsize'] = (3, 3)
plt.style.use('seaborn-v0_8-pastel')  # Use the correct style name with the version prefix
plt.rcParams['figure.dpi'] = 150

# Define color palettes
c0 = sns.color_palette()[0]
c1 = sns.color_palette()[1]
c2 = sns.color_palette()[2]

# Colormaps for classification visuals
cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])
cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])
cm = plt.cm.RdBu
cm_bright = ListedColormap(['#FF0000', '#0000FF'])

def points_plot(ax, Xtr, Xte, ytr, yte, 
                clf, 
                mesh = True, colorscale = cmap_light, cdiscrete = cmap_bold, 
                alpha = 0.1, psize = 10, 
                zfunc = False, predicted = False):

    try:
        feature_names = Xtr.columns
    except:
        feature_names = None
      
    Xtrain = np.array(Xtr)
    Xtest = np.array(Xte)

    h = 0.02

# create a uniform grid spanning the range of the X values
    X = np.concatenate((Xtrain, Xtest))
    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5
    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                         np.linspace(y_min, y_max, 100))

# predict the target value at each point in the grid
    if zfunc:
        mesh_data = np.c_[xx.ravel(), yy.ravel()]
        if feature_names is not None:
            mesh_data = pd.DataFrame(mesh_data, 
                         columns = feature_names)
        p0 = clf.predict_proba(mesh_data)[:, 0]
        p1 = clf.predict_proba(mesh_data)[:, 1]
        Z = zfunc(p0, p1)

# this method uses the classifier to predict the classes directly
    else:
        mesh_data = np.c_[xx.ravel(), yy.ravel()]
        if feature_names is not None:
            mesh_data = pd.DataFrame(mesh_data, 
                                     columns = feature_names)
        Z = clf.predict(mesh_data)
    ZZ = Z.reshape(xx.shape)

# plt.pcolormesh() creates a shaded result over the grid
    if mesh:
        plt.pcolormesh(xx, yy, ZZ, 
                       cmap = cmap_light, 
                       alpha = alpha, 
                       axes = ax, 
                       shading = 'auto')

# add the points to the plot
    if predicted:
        showtr = clf.predict(Xtr)
        showte = clf.predict(Xte)
    else:
        showtr = ytr
        showte = yte
        
# plot training points
    ax.scatter(Xtrain[:, 0], Xtrain[:, 1], 
               c = showtr - 1, 
               cmap = cmap_bold, 
               s = psize, 
               alpha = alpha, 
               edgecolor = "k")

# plot testing points
    ax.scatter(Xtest[:, 0], Xtest[:, 1],
               c = showte - 1, 
               cmap = cmap_bold, 
               s = psize + 10,
               alpha = alpha, 
               marker = "s")
    ax.set_xlim(xx.min(), xx.max())
    ax.set_ylim(yy.min(), yy.max())
#
    return ax, xx, yy

def points_plot_prob(ax, Xtr, Xte, ytr, yte, 
                     clf, colorscale = cmap_light, cdiscrete = cmap_bold, 
                     ccolor = cm, 
                     alpha = 0.1, psize = 10):
    try:
        feature_names = Xtr.columns
    except:
        feature_names = None
#        
    Xtrain = np.array(Xtr)
    Xtest = np.array(Xte)
#    
    ax, xx, yy = points_plot(ax, Xtr, Xte, ytr, yte,
                         clf,
                         mesh = False, 
                         colorscale = colorscale, cdiscrete = cdiscrete, 
                         psize = psize, alpha = alpha,
                         predicted = True) 
    mesh_data = np.c_[xx.ravel(), yy.ravel()]
    if feature_names is not None:
        mesh_data = pd.DataFrame(mesh_data, 
                     columns = feature_names)    
    Z = clf.predict_proba(mesh_data)[:, 1]
    Z = Z.reshape(xx.shape)
    plt.contourf(xx, yy, Z, cmap = ccolor, alpha = 0.2)
    cs2 = plt.contour(xx, yy, Z, cmap = ccolor, alpha = 0.6)
    plt.clabel(cs2, fmt = '%2.1f', colors = 'k', fontsize = 12)
#
    plt.show()

# Load the heart disease dataset
dflog = pd.read_excel(r"C:\Users\jwhit\OneDrive\Documents\Data Science Course\Logistic Regression\heart.xlsx")
#
print('The data have ', dflog.shape[0], ' rows and ', dflog.shape[1], ' columns\n')
print('column names: \n')
print('\n'.join(list(dflog.columns)))

dflog.head()

for col in list(dflog.columns):
    dflog[col].plot(kind = 'hist', title = col)
    plt.show()

x = dflog['age_yr']
print('first 6 lines of age data:\n', x.head(6))
print('\nsummary statistics of age:\n', x.describe())

y = dflog['resting_BP_mm_Hg']
print('first six lines of blood pressure data:\n', y.head(6))
print('\nsummary statistics of blood pressure:\n', y.describe())

categorical_features = ['sex_M_F',
                        'chest_pain_value',
                        'ECG_value',
                        'ST_slope_peak',
                        'defect_diag']
dflog = pd.get_dummies(dflog, columns = categorical_features)
print('The data have ', dflog.shape[0], ' rows and ', dflog.shape[1], ' columns\n')
print('column names: \n')
print('\n'.join(list(dflog.columns)))

class_counts = dflog['heart_disease'].value_counts()
class_counts

type(class_counts)

class_percentages = pd.Series([(x / dflog.shape[0]) * 100.00 for x in class_counts])
class_percentages

fig, ax = plt.subplots()
ax.bar(class_counts.index, class_counts)
ax.set_xticks([0, 1])
ax.set_xticklabels(class_percentages.index.astype(str) + '\n' + ' ' +
                   class_percentages.round(0).astype(str) + '%')
ax.set_ylabel('Count')
ax.set_xlabel('Heart Disease')
ax.set_title('Heart Disease class distribution\nwhere 1 means presence of heart disease',
              fontsize = 10)
plt.show()

Xtrain, Xtest, ytrain, ytest = train_test_split(dflog[['cholesterol_mg_dl','resting_BP_mm_Hg']],
                                                dflog['heart_disease'],
                                                train_size = 0.80,
                                                random_state = 42)

classifier = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1000)

classifier.fit(Xtrain, ytrain)

print(f'Accuracy on training data: {accuracy_score(classifier.predict(Xtrain), ytrain):.2f}')

print(f'Accuracy on test data: {accuracy_score(classifier.predict(Xtest), ytest):.2f}')

plt.figure()
ax = plt.gca()
ax.set_ylabel('Resting blood pressure (mm Hg)')
ax.set_xlabel('Cholesterol level (mg/dl)')
ax.set_title('Computed Decision Boundary:\n ' +
             'Cholesterol Level (mg/dl) VS Resting Blood Pressure (mm Hg)' +
             '\n Red: Heart Disease | Blue: No Heart Disease' +
             '\n Circles: Training Set | Squares: Testing Set\n',
            fontsize = 10)
_ = points_plot(ax, Xtrain, Xtest, ytrain, ytest, classifier, alpha = 0.2)

print("Classification Report for Training Data")
print(classification_report(ytrain, classifier.predict(Xtrain)))

print("Classification Report for Test Data")
print(classification_report(ytest, classifier.predict(Xtest)))

X = dflog.drop(columns = ['heart_disease'])
print("X: ", type(X), X.shape)

y = dflog['heart_disease']
print("y: ", type(y), y.shape)

list(X.columns)

Xlr, Xtestlr, ylr, ytestlr = train_test_split(X, y, random_state = 2)
print('Training split has ', Xlr.shape[0], ' rows\n',
      'and the corresponding labels have an equal number of values.', 
      '(' + str(len(ylr))+ ')')

print('Test split has ', Xtestlr.shape[0], ' rows\n',
      'and the corresponding labels have an equal number of values.', 
      '(' + str(len(ytestlr)) + ')')

def plot_y_ratios(y, ytest):
    fig, ax = plt.subplots(2, sharex = True)
    ax[0].bar(x = [0, 1], height = [y[y == 0].count(), 
                                    y[y == 1].count()])
    ax[0].set_ylabel('train', fontsize = 8)
    ax[0].set_ylim(0, 125)
    ax[1].bar(x = [0, 1], height = [ytest[ytest == 0].count(),
                                    ytest[ytest == 1].count()])
    ax[1].set_ylabel('test', fontsize = 8)
    ax[1].set_ylim(0, 125)
    ax[1].set_xticks([0, 1])
    ax[0].tick_params(which = 'both', labelsize = 8)
    ax[1].tick_params(which = 'both', labelsize = 8)
    ax[1].set_xlabel('heart disease\n(0 = no disease)', fontsize = 8)
    ax[0].set_title('% heart disease (where 1 means presence of heart diseases):\n' +
                    'train: ' + str(round(100 * (y[y ==1].count()/y.shape[0]), 0)) +
                    '\ntest: ' + str(round(100 * (ytest[ytest ==1].count()/ytest.shape[0]), 0)),
                   fontsize = 10)
    plt.show() 

plot_y_ratios(ylr, ytestlr)

# Perform stratified train/test split
Xlrstrat, Xtestlrstrat, ylrstrat, ytestlrstrat = train_test_split(X, y, random_state=2, stratify=y)
plot_y_ratios(ylrstrat, ytestlrstrat)

# Train logistic regression model with newton-cg solver
clf = LogisticRegression(solver='newton-cg', max_iter=500)
clf.fit(Xlrstrat, ylrstrat)

# Make predictions on training and test sets
y_predict_test = clf.predict(Xtestlrstrat)
y_predict_training = clf.predict(Xlrstrat)

print("[Test] Accuracy score (y_predict_test, ytestlrstrat):",
      f'{accuracy_score(y_predict_test, ytestlrstrat):.2f}')

print("[Test] Accuracy score: (ytestlrstrat, y_predict_test) [**note reversed order]", 
      f'{accuracy_score(ytestlrstrat, y_predict_test):.2f}')

print("[Training] Accuracy score: (ylrstrat, y_predict_training)", 
      f'{accuracy_score(ylrstrat, y_predict_training):.2f}')

# Confusion Matrix for the test set
cm = confusion_matrix(ytestlrstrat, y_predict_test, labels=clf.classes_)
_, ax = plt.subplots()
display_cm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['no heart disease', 'heart disease'])
ax.set_xticks([0, 1])
ax.set_yticks([0, 1])
ax.set_xticklabels(labels=['no heart disease', 'heart disease'], fontsize=8)
ax.set_yticklabels(labels=['no heart disease', 'heart disease'], fontsize=8)
display_cm.plot(ax=ax)

# Print classification reports for training and test sets
print("Classification Report for Training Data")
print(classification_report(ylrstrat, y_predict_training))


print("Classification Report for Test Data")
print(classification_report(ytestlrstrat, y_predict_test))


# Perform multiple train/test splits to observe the effects
training_accuracy = []
test_accuracy = []
accuracy_difference = []

n_splits = 25  # Define the number of trials
clf = LogisticRegression(solver='newton-cg', max_iter=500)  # Define LogisticRegression object

for i in range(n_splits):
    # Perform a stratified train/test split with a different random_state for each iteration
    Xlr, Xtestlr, ylr, ytestlr = train_test_split(X, y, stratify=y, random_state=i)

    # Fit the Classifier on the training set
    clf.fit(Xlr, ylr)
    # Predict labels for the training and test data
    y_predict_training = clf.predict(Xlr)
    y_predict_test = clf.predict(Xtestlr)
    # Save training set accuracy for this split
    tr_accuracy = accuracy_score(y_predict_training, ylr)
    training_accuracy.append(tr_accuracy)
    # Save test set accuracy for this split
    tst_accuracy = accuracy_score(y_predict_test, ytestlr)
    test_accuracy.append(tst_accuracy)
    # Save the difference between the test and training accuracy
    accuracy_difference.append(tst_accuracy - tr_accuracy)

# Plot Training vs Test Accuracy
fig, ax = plt.subplots()
ax.scatter(range(len(training_accuracy)),
           training_accuracy, 
           color='blue', 
           alpha=0.5, 
           label='Train data results')
ax.plot(range(len(training_accuracy)),
        training_accuracy, 
        color='blue', 
        linestyle='-.', 
        linewidth=0.5)
ax.scatter(range(len(test_accuracy)),
           test_accuracy, 
           color='red', 
           alpha=0.35, 
           label='Test data results')
ax.plot(range(len(test_accuracy)),
        test_accuracy, 
        color='red', 
        linestyle='-.', 
        linewidth=0.5)
ax.legend(fontsize=8, loc="lower right")
ax.set_ylabel('Training vs Test Accuracy')
ax.set_ylim(0, 1)
ax.set_xlabel('trial number')
plt.show()

# Plot Accuracy Difference (Test - Train)
fig, ax = plt.subplots()
ax.scatter(range(len(accuracy_difference)),
           accuracy_difference, 
           color='green', 
           label='Difference in Accuracy [test - train]')
ax.plot([0, len(accuracy_difference)], [0, 0], 'red')
ax.legend(fontsize=6)
ax.set_ylabel('Test/Training Accuracy Difference')
ax.set_ylim(-0.25, 0.25)
ax.set_xlabel('trial number')
plt.show()

# Print final classification reports for the last trial
print("[Training Classification Report]")
print(classification_report(ylr, y_predict_training))

print("[Test Classification Report]")
print(classification_report(ytestlr, y_predict_test))

help(LogisticRegression)

# Define a cross-validation scoring function
def cv_score(clf, x, y, score_func=accuracy_score):
    result = 0
    nfold = 5  # Number of folds
    x.reset_index(drop=True, inplace=True)
    y.index = x.index
    for train, test in KFold(nfold, shuffle=True, random_state=42).split(x):
        clf.fit(x.loc[train, :], y[train])
        result += score_func(clf.predict(x.loc[test, :]), y[test])
    return result / nfold

# Compute cross-validation score
clf = LogisticRegression(solver='liblinear', max_iter=500)
score = cv_score(clf, Xlr, ylr)
print(f'Cross-Validation Score: {score:.2f}')

# Define the grid of possible C values
Cs = [0.001, 0.1, 1, 10, 100]

# Store the results
best_C = None
best_score = 0

# Iterate over the list of C values
for C in Cs:
    # Create a logistic regression model with the current value of C
    clf = LogisticRegression(solver='liblinear', max_iter=500, C=C)

    # Calculate the cross-validation score using the cv_score function
    avg_score = cv_score(clf, Xlr, ylr)

    # Print the current C value and its average score
    print(f'C: {C}, Average CV Score: {avg_score:.2f}')

    # Check if this is the best score so far
    if avg_score > best_score:
        best_C = C
        best_score = avg_score

# Print the best C value and the corresponding best score
print(f'\nBest C value: {best_C}')
print(f'Best average CV score: {best_score:.2f}')

# Step 1: Train the Logistic Regression model with the best C value
best_clf = LogisticRegression(solver='liblinear', max_iter=500, C=best_C)
best_clf.fit(Xlr, ylr)

# Step 2: Calculate accuracy on the test set
test_accuracy = accuracy_score(best_clf.predict(Xtestlr), ytestlr)

# Print the results
print(f'Best C value from cross-validation: {best_C}')
print(f'Test Accuracy with best C: {test_accuracy:.2f}')

# 1.) Do you think that obtaining a lower test accuracy with the "best" C is a problem?
# A.) Not necessarily. It's common for the performance on the test set to fluctuate slightly because the test set is unseen data that the model has never trained on.
# 2.) Why do we need to do this whole cross-validation and grid search process?
# A.) Cross-validation helps ensure that the model generalizes well across different subsets of the data, preventing overfitting to a specific train/test split.
# While grid search is used to find the best hyperparameters (like C) that allow the model to balance bias and variance. Without this process, we would rely on arbitrary or default hyperparameters that may not be optimal for the dataset.

from sklearn.model_selection import GridSearchCV

# Step 1: Define the logistic regression model and the parameter grid
param_grid = {'C': [0.001, 0.1, 1, 10, 100]}
clf = LogisticRegression(solver='liblinear', max_iter=500)

# Step 2: Initialize GridSearchCV with 5-fold cross-validation
grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')

# Step 3: Fit GridSearchCV on the training set
grid_search.fit(Xlr, ylr)

# Step 4: Print the best parameters and the best cross-validation score
print(f'Best C value from GridSearchCV: {grid_search.best_params_["C"]}')
print(f'Best cross-validation score from GridSearchCV: {grid_search.best_score_:.2f}')

# Step 5: Evaluate the model obtained from GridSearchCV on the test set
best_model = grid_search.best_estimator_
test_accuracy = accuracy_score(best_model.predict(Xtestlr), ytestlr)
print(f'Test Accuracy with the best C from GridSearchCV: {test_accuracy:.2f}')

#1.) Does GridSearchCV give the same best C?
#A.) Yes, it consistency shows that both the manual approach and GridSearchCV lead to the same optimal model for this dataset, reinforcing that C=1 offers the best balance between regularization and model performance.
#2.) How does the model perform on the test set?
#A.) The test accuracy is slightly better because cross-validation averages over multiple training splits, which can introduce a little more variability, while the test set provides a more direct evaluation of how the model performs on unseen data.

h = lambda z: 1. / (1 + np.exp(-z))
zs = np.arange(-5, 5, 0.1)
fig, ax = plt.subplots()
ax.plot(zs, h(zs), alpha=0.5)
ax.set_ylabel('Sigmoid Output')
ax.set_xlabel('Sigmoid Input')
plt.show()

train, Xtest, ytrain, ytest = \
    train_test_split(dflog[['cholesterol_mg_dl','resting_BP_mm_Hg']],
                     dflog['heart_disease'],
                     train_size = 0.80,
                     random_state = 42)
classifier = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1000)
classifier.fit(Xtrain, ytrain)

plt.figure()
ax = plt.gca()
ax.set_ylabel('Resting blood pressure (mm Hg)')
ax.set_xlabel('Cholesterol level (mg/dl)')
_ = points_plot_prob(ax, Xtrain, Xtest, ytrain, ytest, classifier, psize = 20, alpha = 0.1)
